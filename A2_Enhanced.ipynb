{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2: Enhanced Linear Regression - Improved Pipeline\n",
    "**Student ID: st126010 - Htut Ko Ko**\n",
    "\n",
    "This notebook implements enhanced linear regression with polynomial features and Lasso regularization using proper data pipeline: split > impute > scale > polynomial > train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso as SklearnLasso\n",
    "from LinearRegression import LinearRegression, Ridge \n",
    "import mlflow\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8128, 13)\n",
      "Columns: ['name', 'year', 'selling_price', 'km_driven', 'fuel', 'seller_type', 'transmission', 'owner', 'mileage', 'engine', 'max_power', 'torque', 'seats']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.4 kmpl</td>\n",
       "      <td>1248 CC</td>\n",
       "      <td>74 bhp</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14 kmpl</td>\n",
       "      <td>1498 CC</td>\n",
       "      <td>103.52 bhp</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda City 2017-2020 EXi</td>\n",
       "      <td>2006</td>\n",
       "      <td>158000</td>\n",
       "      <td>140000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Third Owner</td>\n",
       "      <td>17.7 kmpl</td>\n",
       "      <td>1497 CC</td>\n",
       "      <td>78 bhp</td>\n",
       "      <td>12.7@ 2,700(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai i20 Sportz Diesel</td>\n",
       "      <td>2010</td>\n",
       "      <td>225000</td>\n",
       "      <td>127000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.0 kmpl</td>\n",
       "      <td>1396 CC</td>\n",
       "      <td>90 bhp</td>\n",
       "      <td>22.4 kgm at 1750-2750rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti Swift VXI BSIII</td>\n",
       "      <td>2007</td>\n",
       "      <td>130000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>16.1 kmpl</td>\n",
       "      <td>1298 CC</td>\n",
       "      <td>88.2 bhp</td>\n",
       "      <td>11.5@ 4,500(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "2      Honda City 2017-2020 EXi  2006         158000     140000  Petrol   \n",
       "3     Hyundai i20 Sportz Diesel  2010         225000     127000  Diesel   \n",
       "4        Maruti Swift VXI BSIII  2007         130000     120000  Petrol   \n",
       "\n",
       "  seller_type transmission         owner     mileage   engine   max_power  \\\n",
       "0  Individual       Manual   First Owner   23.4 kmpl  1248 CC      74 bhp   \n",
       "1  Individual       Manual  Second Owner  21.14 kmpl  1498 CC  103.52 bhp   \n",
       "2  Individual       Manual   Third Owner   17.7 kmpl  1497 CC      78 bhp   \n",
       "3  Individual       Manual   First Owner   23.0 kmpl  1396 CC      90 bhp   \n",
       "4  Individual       Manual   First Owner   16.1 kmpl  1298 CC    88.2 bhp   \n",
       "\n",
       "                     torque  seats  \n",
       "0            190Nm@ 2000rpm    5.0  \n",
       "1       250Nm@ 1500-2500rpm    5.0  \n",
       "2     12.7@ 2,700(kgm@ rpm)    5.0  \n",
       "3  22.4 kgm at 1750-2750rpm    5.0  \n",
       "4     11.5@ 4,500(kgm@ rpm)    5.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('Cars.csv')\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8128 entries, 0 to 8127\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   name           8128 non-null   object \n",
      " 1   year           8128 non-null   int64  \n",
      " 2   selling_price  8128 non-null   int64  \n",
      " 3   km_driven      8128 non-null   int64  \n",
      " 4   fuel           8128 non-null   object \n",
      " 5   seller_type    8128 non-null   object \n",
      " 6   transmission   8128 non-null   object \n",
      " 7   owner          8128 non-null   object \n",
      " 8   mileage        7907 non-null   object \n",
      " 9   engine         7907 non-null   object \n",
      " 10  max_power      7913 non-null   object \n",
      " 11  torque         7906 non-null   object \n",
      " 12  seats          7907 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(9)\n",
      "memory usage: 825.6+ KB\n",
      "\n",
      "Missing values before cleaning:\n",
      "name               0\n",
      "year               0\n",
      "selling_price      0\n",
      "km_driven          0\n",
      "fuel               0\n",
      "seller_type        0\n",
      "transmission       0\n",
      "owner              0\n",
      "mileage          221\n",
      "engine           221\n",
      "max_power        215\n",
      "torque           222\n",
      "seats            221\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data info and missing values\n",
    "print(\"Dataset Info:\")\n",
    "data.info()\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed\n",
      "Shape after cleaning: (8128, 11)\n",
      "\n",
      "Missing values after cleaning:\n",
      "year               0\n",
      "selling_price      0\n",
      "km_driven          0\n",
      "fuel               0\n",
      "seller_type        0\n",
      "transmission       0\n",
      "owner              0\n",
      "mileage          221\n",
      "engine           221\n",
      "max_power        216\n",
      "seats            221\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean data - extract numeric values from string columns\n",
    "data['mileage'] = data['mileage'].str.extract('(\\\\d+\\\\.?\\\\d*)').astype(float)\n",
    "data['engine'] = data['engine'].str.extract('(\\\\d+)').astype(float)\n",
    "data['max_power'] = data['max_power'].str.extract('(\\\\d+\\\\.?\\\\d*)').astype(float)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "data = data.drop(columns=['name', 'torque'])\n",
    "\n",
    "print(\"Data cleaning completed\")\n",
    "print(f\"Shape after cleaning: {data.shape}\")\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['year', 'km_driven', 'mileage', 'engine', 'max_power', 'seats', 'fuel', 'seller_type', 'transmission', 'owner']\n",
      "X shape: (8128, 10)\n",
      "y shape: (8128,)\n",
      "Missing values in features:\n",
      "year              0\n",
      "km_driven         0\n",
      "mileage         221\n",
      "engine          221\n",
      "max_power       216\n",
      "seats           221\n",
      "fuel              0\n",
      "seller_type       0\n",
      "transmission      0\n",
      "owner             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "numeric_columns = ['year', 'km_driven', 'mileage', 'engine', 'max_power', 'seats']\n",
    "categorical_columns = ['fuel', 'seller_type', 'transmission', 'owner']\n",
    "feature_names = numeric_columns + categorical_columns\n",
    "\n",
    "X = data[feature_names].copy()\n",
    "y = data['selling_price']\n",
    "\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Missing values in features:\")\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (6502, 10)\n",
      "Test set: (1626, 10)\n",
      "Training missing values: 677\n",
      "Test missing values: 202\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Split data FIRST (before any preprocessing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Training missing values: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Test missing values: {X_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Missing values imputed\n",
      "Training missing values after imputation: 0\n",
      "Test missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Impute missing values (fit on train, transform both)\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Impute numeric columns\n",
    "X_train[numeric_columns] = imputer_num.fit_transform(X_train[numeric_columns])\n",
    "X_test[numeric_columns] = imputer_num.transform(X_test[numeric_columns])\n",
    "\n",
    "# Impute categorical columns\n",
    "X_train[categorical_columns] = imputer_cat.fit_transform(X_train[categorical_columns])\n",
    "X_test[categorical_columns] = imputer_cat.transform(X_test[categorical_columns])\n",
    "\n",
    "print(\"✅ Missing values imputed\")\n",
    "print(f\"Training missing values after imputation: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Test missing values after imputation: {X_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Categorical variables encoded\n",
      "Label encoders created for: ['fuel', 'seller_type', 'transmission', 'owner']\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Encode categorical variables (fit on train, transform both)\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"✅ Categorical variables encoded\")\n",
    "print(f\"Label encoders created for: {list(label_encoders.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features scaled\n",
      "Scaled training set shape: (6502, 10)\n",
      "Scaled test set shape: (1626, 10)\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Scale features (fit on train, transform both)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"✅ Features scaled\")\n",
    "print(f\"Scaled training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test set shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Polynomial features created\n",
      "Polynomial training set shape: (6502, 65)\n",
      "Polynomial test set shape: (1626, 65)\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Create polynomial features (fit on train, transform both)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "print(\"✅ Polynomial features created\")\n",
    "print(f\"Polynomial training set shape: {X_train_poly.shape}\")\n",
    "print(f\"Polynomial test set shape: {X_test_poly.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation function\n",
    "def cross_validate_model(model, X_data, y_data, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation for a given instantiated model.\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    r2_scores = []\n",
    "    mse_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_data)):\n",
    "        # Split data for this fold\n",
    "        X_fold_train, X_fold_val = X_data[train_idx], X_data[val_idx]\n",
    "        y_fold_train, y_fold_val = y_data.iloc[train_idx], y_data.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_fold_train, y_fold_val.values)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        r2 = model.r2(X_fold_val, y_fold_val.values)\n",
    "        mse = mean_squared_error(y_fold_val.values, y_pred)\n",
    "        \n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "    \n",
    "    return {\n",
    "        'mean_r2': np.mean(r2_scores),\n",
    "        'std_r2': np.std(r2_scores),\n",
    "        'mean_mse': np.mean(mse_scores),\n",
    "        'std_mse': np.std(mse_scores),\n",
    "    }\n",
    "\n",
    "print(\"Cross-validation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment configurations defined!\n"
     ]
    }
   ],
   "source": [
    "# Define experiment configurations\n",
    "experiments = {\n",
    "    'linear_polynomial': {\n",
    "        'model': LinearRegression(),\n",
    "        'data': X_train_poly,\n",
    "        'description': 'Linear Regression with Polynomial Features'\n",
    "    },\n",
    "    'ridge_polynomial': {\n",
    "        'model': Ridge(alpha=0.1),\n",
    "        'data': X_train_poly,\n",
    "        'description': 'Ridge Regression with Polynomial Features'\n",
    "    },\n",
    "    'lasso_polynomial': {\n",
    "        'model': SklearnLasso(alpha=0.1, random_state=42),\n",
    "        'data': X_train_poly,\n",
    "        'description': 'Lasso Regression with Polynomial Features'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Experiment configurations defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with cross-validation...\n",
      "\n",
      "Running linear_polynomial: Linear Regression with Polynomial Features\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5201,) (1301,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[1;32m     15\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m'\u001b[39m: exp_name,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtype\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_mse\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_mse\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m }\n",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m, in \u001b[0;36mcross_validate_model\u001b[0;34m(model, X_data, y_data, cv_folds)\u001b[0m\n\u001b[1;32m     13\u001b[0m y_fold_train, y_fold_val \u001b[38;5;241m=\u001b[39m y_data\u001b[38;5;241m.\u001b[39miloc[train_idx], y_data\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fold_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fold_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Predict and evaluate\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_fold_val)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-AsianInstituteofTechnology/AIT_Study/AT82.3_Machine_Learning/A3/LinearRegression.py:53\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, feature_names)\u001b[0m\n\u001b[1;32m     50\u001b[0m X_b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[np\u001b[38;5;241m.\u001b[39mones((m, \u001b[38;5;241m1\u001b[39m)), X]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_batch_gd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmini-batch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_mini_batch_gd(X_b, y)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-AsianInstituteofTechnology/AIT_Study/AT82.3_Machine_Learning/A3/LinearRegression.py:62\u001b[0m, in \u001b[0;36mLinearRegression._fit_batch_gd\u001b[0;34m(self, X_b, y)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[1;32m     61\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m X_b\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta)\n\u001b[0;32m---> 62\u001b[0m     residuals \u001b[38;5;241m=\u001b[39m \u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n\u001b[1;32m     63\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m X_b\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(residuals) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregularization:\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5201,) (1301,) "
     ]
    }
   ],
   "source": [
    "# Run experiments with cross-validation\n",
    "results = []\n",
    "best_model = None\n",
    "best_score = -np.inf\n",
    "\n",
    "print(\"Running experiments with cross-validation...\\n\")\n",
    "\n",
    "for exp_name, config in experiments.items():\n",
    "    print(f\"Running {exp_name}: {config['description']}\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_validate_model(config['model'], config['data'], y_train)\n",
    "    \n",
    "    # Store results\n",
    "    result = {\n",
    "        'experiment_name': exp_name,\n",
    "        'model_type': type(config['model']).__name__,\n",
    "        'mean_r2': cv_results['mean_r2'],\n",
    "        'std_r2': cv_results['std_r2'],\n",
    "        'mean_mse': cv_results['mean_mse'],\n",
    "        'std_mse': cv_results['std_mse']\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    # Track best model\n",
    "    if cv_results['mean_r2'] > best_score:\n",
    "        best_score = cv_results['mean_r2']\n",
    "        best_model = config\n",
    "        best_model['name'] = exp_name\n",
    "    \n",
    "    print(f\"  Mean R²: {cv_results['mean_r2']:.4f} (±{cv_results['std_r2']:.4f})\")\n",
    "    print(f\"  Mean MSE: {cv_results['mean_mse']:.2f} (±{cv_results['std_mse']:.2f})\\n\")\n",
    "\n",
    "print(f\"Best model: {best_model['name']} with R² = {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the best model on the test set\n",
    "if best_model:\n",
    "    print(\"Training Best Model on Full Dataset\")\n",
    "    print(f\"Best Configuration: {best_model['name']}\")\n",
    "    \n",
    "    # Train on full training set\n",
    "    final_model = best_model['model']\n",
    "    final_model.fit(best_model['data'], y_train.values)\n",
    "    \n",
    "    # Predict on test set\n",
    "    if best_model['name'] == 'lasso_polynomial':\n",
    "        y_pred_test = final_model.predict(X_test_poly)\n",
    "        test_r2 = final_model.r2(X_test_poly, y_test.values)\n",
    "    else:\n",
    "        y_pred_test = final_model.predict(X_test_poly)\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"- Test R2 Score: {test_r2:.4f}\")\n",
    "    print(f\"- Test MSE: {test_mse:.2f}\")\n",
    "    \n",
    "    # Save the model and all necessary artifacts\n",
    "    model_artifacts = {\n",
    "        'model': final_model,\n",
    "        'scaler': scaler,\n",
    "        'poly': poly,\n",
    "        'imputer_num': imputer_num,\n",
    "        'imputer_cat': imputer_cat,\n",
    "        'label_encoders': label_encoders,\n",
    "        'feature_names': feature_names,\n",
    "        'metrics': {\n",
    "            'test_r2': test_r2,\n",
    "            'test_mse': test_mse,\n",
    "            'cv_mean_r2': best_score\n",
    "        },\n",
    "        'model_type': best_model['name']\n",
    "    }\n",
    "    \n",
    "    with open('a2_model_artifacts.pkl', 'wb') as f:\n",
    "        pickle.dump(model_artifacts, f)\n",
    "    \n",
    "    print(\"\\nModel saved as 'a2_model_artifacts.pkl'\")\n",
    "    print(f\"🎯 Final Test R²: {test_r2:.4f}\")\n",
    "    print(\"🔄 Pipeline: Load → Clean → Split → Impute → Scale → Polynomial → Train → Evaluate\")\n",
    "else:\n",
    "    print(\"No experiments were run successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "if best_model and 'y_pred_test' in locals():\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_test, y_pred_test, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Price')\n",
    "    plt.ylabel('Predicted Price')\n",
    "    plt.title(f'A2: Actual vs Predicted (R² = {test_r2:.4f})')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    residuals = y_test - y_pred_test\n",
    "    plt.scatter(y_pred_test, residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Predicted Price')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display results summary\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nExperiment Results Summary:\")\n",
    "    print(results_df[['experiment_name', 'model_type', 'mean_r2', 'std_r2']].round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
