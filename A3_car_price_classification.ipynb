{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e3d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd66d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7edbf70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data from your A2 notebook\n",
    "data = pd.read_csv('Cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b4756b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.4 kmpl</td>\n",
       "      <td>1248 CC</td>\n",
       "      <td>74 bhp</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14 kmpl</td>\n",
       "      <td>1498 CC</td>\n",
       "      <td>103.52 bhp</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda City 2017-2020 EXi</td>\n",
       "      <td>2006</td>\n",
       "      <td>158000</td>\n",
       "      <td>140000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Third Owner</td>\n",
       "      <td>17.7 kmpl</td>\n",
       "      <td>1497 CC</td>\n",
       "      <td>78 bhp</td>\n",
       "      <td>12.7@ 2,700(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai i20 Sportz Diesel</td>\n",
       "      <td>2010</td>\n",
       "      <td>225000</td>\n",
       "      <td>127000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.0 kmpl</td>\n",
       "      <td>1396 CC</td>\n",
       "      <td>90 bhp</td>\n",
       "      <td>22.4 kgm at 1750-2750rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti Swift VXI BSIII</td>\n",
       "      <td>2007</td>\n",
       "      <td>130000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>16.1 kmpl</td>\n",
       "      <td>1298 CC</td>\n",
       "      <td>88.2 bhp</td>\n",
       "      <td>11.5@ 4,500(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "2      Honda City 2017-2020 EXi  2006         158000     140000  Petrol   \n",
       "3     Hyundai i20 Sportz Diesel  2010         225000     127000  Diesel   \n",
       "4        Maruti Swift VXI BSIII  2007         130000     120000  Petrol   \n",
       "\n",
       "  seller_type transmission         owner     mileage   engine   max_power  \\\n",
       "0  Individual       Manual   First Owner   23.4 kmpl  1248 CC      74 bhp   \n",
       "1  Individual       Manual  Second Owner  21.14 kmpl  1498 CC  103.52 bhp   \n",
       "2  Individual       Manual   Third Owner   17.7 kmpl  1497 CC      78 bhp   \n",
       "3  Individual       Manual   First Owner   23.0 kmpl  1396 CC      90 bhp   \n",
       "4  Individual       Manual   First Owner   16.1 kmpl  1298 CC    88.2 bhp   \n",
       "\n",
       "                     torque  seats  \n",
       "0            190Nm@ 2000rpm    5.0  \n",
       "1       250Nm@ 1500-2500rpm    5.0  \n",
       "2     12.7@ 2,700(kgm@ rpm)    5.0  \n",
       "3  22.4 kgm at 1750-2750rpm    5.0  \n",
       "4     11.5@ 4,500(kgm@ rpm)    5.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ae4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean non-numeric columns and drop irrelevant ones\n",
    "data['mileage'] = data['mileage'].str.extract('(\\d+\\.?\\d*)').astype(float)\n",
    "data['engine'] = data['engine'].str.extract('(\\d+)').astype(float)\n",
    "data['max_power'] = data['max_power'].str.extract('(\\d+\\.?\\d*)').astype(float)\n",
    "data = data.drop(columns=['torque', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cfc5d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8128 entries, 0 to 8127\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   year           8128 non-null   int64  \n",
      " 1   selling_price  8128 non-null   int64  \n",
      " 2   km_driven      8128 non-null   int64  \n",
      " 3   fuel           8128 non-null   object \n",
      " 4   seller_type    8128 non-null   object \n",
      " 5   transmission   8128 non-null   object \n",
      " 6   owner          8128 non-null   object \n",
      " 7   mileage        7907 non-null   float64\n",
      " 8   engine         7907 non-null   float64\n",
      " 9   max_power      7912 non-null   float64\n",
      " 10  seats          7907 non-null   float64\n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 698.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f065348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for both numeric and categorical columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "numeric_columns = ['year', 'km_driven', 'mileage', 'engine', 'max_power', 'seats']\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "data[numeric_columns] = imputer_num.fit_transform(data[numeric_columns])\n",
    "\n",
    "categorical_columns = ['fuel', 'seller_type', 'transmission', 'owner']\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_columns] = imputer_cat.fit_transform(data[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26062331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any remaining rows with NaN values (a safeguard)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14d56053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8128 entries, 0 to 8127\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   year           8128 non-null   float64\n",
      " 1   selling_price  8128 non-null   int64  \n",
      " 2   km_driven      8128 non-null   float64\n",
      " 3   fuel           8128 non-null   object \n",
      " 4   seller_type    8128 non-null   object \n",
      " 5   transmission   8128 non-null   object \n",
      " 6   owner          8128 non-null   object \n",
      " 7   mileage        8128 non-null   float64\n",
      " 8   engine         8128 non-null   float64\n",
      " 9   max_power      8128 non-null   float64\n",
      " 10  seats          8128 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 698.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "053188d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8128.000000</td>\n",
       "      <td>8.128000e+03</td>\n",
       "      <td>8.128000e+03</td>\n",
       "      <td>8128.000000</td>\n",
       "      <td>8128.000000</td>\n",
       "      <td>8128.000000</td>\n",
       "      <td>8128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2013.804011</td>\n",
       "      <td>6.382718e+05</td>\n",
       "      <td>6.981951e+04</td>\n",
       "      <td>19.418783</td>\n",
       "      <td>1458.625016</td>\n",
       "      <td>91.517919</td>\n",
       "      <td>5.416719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.044249</td>\n",
       "      <td>8.062534e+05</td>\n",
       "      <td>5.655055e+04</td>\n",
       "      <td>3.981875</td>\n",
       "      <td>497.017504</td>\n",
       "      <td>35.343246</td>\n",
       "      <td>0.946450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1983.000000</td>\n",
       "      <td>2.999900e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>624.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>2.549990e+05</td>\n",
       "      <td>3.500000e+04</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>1197.000000</td>\n",
       "      <td>68.100000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>19.418783</td>\n",
       "      <td>1248.000000</td>\n",
       "      <td>83.100000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>6.750000e+05</td>\n",
       "      <td>9.800000e+04</td>\n",
       "      <td>22.277500</td>\n",
       "      <td>1582.000000</td>\n",
       "      <td>101.250000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>2.360457e+06</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>3604.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year  selling_price     km_driven      mileage       engine  \\\n",
       "count  8128.000000   8.128000e+03  8.128000e+03  8128.000000  8128.000000   \n",
       "mean   2013.804011   6.382718e+05  6.981951e+04    19.418783  1458.625016   \n",
       "std       4.044249   8.062534e+05  5.655055e+04     3.981875   497.017504   \n",
       "min    1983.000000   2.999900e+04  1.000000e+00     0.000000   624.000000   \n",
       "25%    2011.000000   2.549990e+05  3.500000e+04    16.800000  1197.000000   \n",
       "50%    2015.000000   4.500000e+05  6.000000e+04    19.418783  1248.000000   \n",
       "75%    2017.000000   6.750000e+05  9.800000e+04    22.277500  1582.000000   \n",
       "max    2020.000000   1.000000e+07  2.360457e+06    42.000000  3604.000000   \n",
       "\n",
       "         max_power        seats  \n",
       "count  8128.000000  8128.000000  \n",
       "mean     91.517919     5.416719  \n",
       "std      35.343246     0.946450  \n",
       "min       0.000000     2.000000  \n",
       "25%      68.100000     5.000000  \n",
       "50%      83.100000     5.000000  \n",
       "75%     101.250000     5.000000  \n",
       "max     400.000000    14.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3b91617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Car Price Analysis from Dataset\n",
      "==================================================\n",
      "Total cars: 8128\n",
      "Price range: 29,999 - 10,000,000\n",
      "Mean price: 638,272\n",
      "Median price: 450,000\n",
      "\n",
      "Price Percentiles:\n",
      "  10th percentile: 150,000\n",
      "  25th percentile: 254,999\n",
      "  50th percentile: 450,000\n",
      "  75th percentile: 675,000\n",
      "  90th percentile: 1,025,000\n",
      "  95th percentile: 1,950,000\n",
      "  99th percentile: 5,200,000\n",
      "\n",
      "üìä Quartile-based Price Classes:\n",
      "  Class 0: ‚â§ 254,999\n",
      "  Class 1: 254,999 - 450,000\n",
      "  Class 2: 450,000 - 675,000\n",
      "  Class 3: > 675,000\n"
     ]
    }
   ],
   "source": [
    "# Price Range Analysis for Classification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"üîç Car Price Analysis from Dataset\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic price statistics\n",
    "prices = data['selling_price']\n",
    "print(f\"Total cars: {len(data)}\")\n",
    "print(f\"Price range: {prices.min():,.0f} - {prices.max():,.0f}\")\n",
    "print(f\"Mean price: {prices.mean():,.0f}\")\n",
    "print(f\"Median price: {prices.median():,.0f}\")\n",
    "\n",
    "# Percentiles analysis\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "print(f\"\\nPrice Percentiles:\")\n",
    "for p in percentiles:\n",
    "    value = prices.quantile(p/100)\n",
    "    print(f\"  {p}th percentile: {value:,.0f}\")\n",
    "\n",
    "# Define and analyze price classes\n",
    "q25, q50, q75 = prices.quantile([0.25, 0.50, 0.75])\n",
    "print(f\"\\nüìä Quartile-based Price Classes:\")\n",
    "print(f\"  Class 0: ‚â§ {q25:,.0f}\")\n",
    "print(f\"  Class 1: {q25:,.0f} - {q50:,.0f}\")\n",
    "print(f\"  Class 2: {q50:,.0f} - {q75:,.0f}\")\n",
    "print(f\"  Class 3: > {q75:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "410dfd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of price classes:\n",
      "price_class\n",
      "1    2142\n",
      "0    2044\n",
      "3    2021\n",
      "2    1921\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert the regression problem into a 4-class classification problem\n",
    "# can adjust the bins based on data distribution\n",
    "bins = [0, 254999, 450000, 675000, np.inf]\n",
    "labels = [0, 1, 2, 3]\n",
    "data['price_class'] = pd.cut(data['selling_price'], bins=bins, labels=labels)\n",
    "print(\"Distribution of price classes:\")\n",
    "print(data['price_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec15be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical columns using LabelEncoder\n",
    "for col in categorical_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    data[col] = label_encoder.fit_transform(data[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b7cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_names = numeric_columns + categorical_columns\n",
    "X = data[feature_names]\n",
    "y = data['price_class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c06db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea50297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "087e757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data preparation for classification complete.\n"
     ]
    }
   ],
   "source": [
    "# Create polynomial features for specific experiments\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "print(\"\\nData preparation for classification complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41f2b0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom metric functions defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Custom Metric Functions ---\n",
    "def custom_classification_metrics(y_true, y_pred, n_classes):\n",
    "    \"\"\"\n",
    "    Calculates custom accuracy, precision, recall, and f1-score.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Accuracy\n",
    "    metrics['accuracy'] = np.mean(y_true == y_pred)\n",
    "    \n",
    "    # Confusion Matrix for other metrics\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        cm[true_label, pred_label] += 1\n",
    "    \n",
    "    # Per-class metrics\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c, c]\n",
    "        fp = np.sum(cm[:, c]) - tp\n",
    "        fn = np.sum(cm[c, :]) - tp\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        \n",
    "    metrics['precision_per_class'] = precisions\n",
    "    metrics['recall_per_class'] = recalls\n",
    "    metrics['f1_per_class'] = f1s\n",
    "\n",
    "    # Macro-averaged metrics\n",
    "    metrics['macro_precision'] = np.mean(precisions)\n",
    "    metrics['macro_recall'] = np.mean(recalls)\n",
    "    metrics['macro_f1'] = np.mean(f1s)\n",
    "\n",
    "    # Weighted-averaged metrics\n",
    "    class_counts = np.bincount(y_true, minlength=n_classes)\n",
    "    total_samples = len(y_true)\n",
    "    weights = class_counts / total_samples\n",
    "    \n",
    "    metrics['weighted_precision'] = np.sum(np.array(precisions) * weights)\n",
    "    metrics['weighted_recall'] = np.sum(np.array(recalls) * weights)\n",
    "    metrics['weighted_f1'] = np.sum(np.array(f1s) * weights)\n",
    "    \n",
    "    return metrics\n",
    "print(\"Custom metric functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac6d0c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Metrics Output:\n",
      "Accuracy: 0.6747\n",
      "Macro F1: 0.6793\n",
      "\n",
      "Scikit-learn's Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82       409\n",
      "           1       0.59      0.60      0.60       449\n",
      "           2       0.51      0.55      0.53       383\n",
      "           3       0.80      0.75      0.78       385\n",
      "\n",
      "    accuracy                           0.67      1626\n",
      "   macro avg       0.68      0.68      0.68      1626\n",
      "weighted avg       0.68      0.67      0.68      1626\n",
      "\n",
      "\n",
      "Comparison of custom and scikit-learn reports confirms that the custom functions are correctly implemented.\n"
     ]
    }
   ],
   "source": [
    "# --- Scikit-learn Comparison ---\n",
    "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression\n",
    "from sklearn.metrics import classification_report as sklearn_classification_report\n",
    "# use a dummy model to verify the metrics\n",
    "dummy_model = SklearnLogisticRegression(random_state=42, solver='lbfgs', multi_class='multinomial')\n",
    "dummy_model.fit(X_train_scaled, y_train)\n",
    "y_pred_dummy = dummy_model.predict(X_test_scaled)\n",
    "\n",
    "# Get custom metrics\n",
    "custom_metrics = custom_classification_metrics(y_test, y_pred_dummy, n_classes=4)\n",
    "print(\"\\nCustom Metrics Output:\")\n",
    "print(f\"Accuracy: {custom_metrics['accuracy']:.4f}\")\n",
    "print(f\"Macro F1: {custom_metrics['macro_f1']:.4f}\")\n",
    "\n",
    "# Get scikit-learn's report\n",
    "print(\"\\nScikit-learn's Classification Report:\")\n",
    "print(sklearn_classification_report(y_test, y_pred_dummy))\n",
    "\n",
    "print(\"\\nComparison of custom and scikit-learn reports confirms that the custom functions are correctly implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2b9569e-56dd-4ad3-84b3-47d76d49894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: http://mlflow.ml.brain.cs.ait.ac.th/\n",
      "Current experiment: st126010-a3\n"
     ]
    }
   ],
   "source": [
    "# --- Corrected MLflow Setup and Experiment Loop ---\n",
    "import mlflow\n",
    "import pickle\n",
    "import warnings\n",
    "from LogisticRegression import LogisticRegression\n",
    "import os\n",
    "\n",
    "# NOTE: Make sure these environment variables are set before running the notebook.\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow.ml.brain.cs.ait.ac.th/\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"admin\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"password\"\n",
    "\n",
    "experiment_name = \"st126010-a3\"  \n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Current experiment: {mlflow.get_experiment_by_name(experiment_name).name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfbc7380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running classification experiments...\n",
      "Run 0e1342a99f3a4d709e536bee109a13d9 complete. Accuracy: 0.5984\n",
      "üèÉ View run none-zeros-0.01-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/0e1342a99f3a4d709e536bee109a13d9\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run bf3df4bf92464039bb58c473d8e1b4b1 complete. Accuracy: 0.5990\n",
      "üèÉ View run none-xavier-0.01-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/bf3df4bf92464039bb58c473d8e1b4b1\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run b0842465f7ad40f3ba7a914acd902529 complete. Accuracy: 0.5664\n",
      "üèÉ View run none-zeros-0.001-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/b0842465f7ad40f3ba7a914acd902529\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 48dd258de8f045eaaac170bfb0149aeb complete. Accuracy: 0.4951\n",
      "üèÉ View run none-xavier-0.001-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/48dd258de8f045eaaac170bfb0149aeb\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 22e6cca5a7ed4154bd6f3f2198f1dfa6 complete. Accuracy: 0.5566\n",
      "üèÉ View run none-zeros-0.0001-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/22e6cca5a7ed4154bd6f3f2198f1dfa6\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 870e44b3535441ee9b58c9719742c52f complete. Accuracy: 0.3690\n",
      "üèÉ View run none-xavier-0.0001-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/870e44b3535441ee9b58c9719742c52f\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run f646cfcb3bfe4dce8519c92ddbd28ef7 complete. Accuracy: 0.5984\n",
      "üèÉ View run ridge-zeros-0.01-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/f646cfcb3bfe4dce8519c92ddbd28ef7\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run bccc57ba66ba4aa1bd2091ad229b8f85 complete. Accuracy: 0.5984\n",
      "üèÉ View run ridge-xavier-0.01-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/bccc57ba66ba4aa1bd2091ad229b8f85\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 0a5c7c35e2194c8e996a557345bdf2c3 complete. Accuracy: 0.5664\n",
      "üèÉ View run ridge-zeros-0.001-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/0a5c7c35e2194c8e996a557345bdf2c3\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run a97175ecc32649b298cafe0e67090997 complete. Accuracy: 0.5351\n",
      "üèÉ View run ridge-xavier-0.001-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/a97175ecc32649b298cafe0e67090997\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run bb872d2e19cd4e46bf00180ec79ab578 complete. Accuracy: 0.5566\n",
      "üèÉ View run ridge-zeros-0.0001-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/bb872d2e19cd4e46bf00180ec79ab578\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run d24f3ef139504254a9395e5c24c35d1d complete. Accuracy: 0.3419\n",
      "üèÉ View run ridge-xavier-0.0001-lambda0.01 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/d24f3ef139504254a9395e5c24c35d1d\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run aec963982ef5408e81f825430dd424cd complete. Accuracy: 0.5984\n",
      "üèÉ View run ridge-zeros-0.01-lambda0.1 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/aec963982ef5408e81f825430dd424cd\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 995efa9ef7924ce19effdf00cd81d786 complete. Accuracy: 0.5984\n",
      "üèÉ View run ridge-xavier-0.01-lambda0.1 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/995efa9ef7924ce19effdf00cd81d786\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run e4200ce8dd954c43a36134b992e9ee23 complete. Accuracy: 0.5664\n",
      "üèÉ View run ridge-zeros-0.001-lambda0.1 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/e4200ce8dd954c43a36134b992e9ee23\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run ccb20661901d4c58a79efa4c218de07e complete. Accuracy: 0.5221\n",
      "üèÉ View run ridge-xavier-0.001-lambda0.1 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/ccb20661901d4c58a79efa4c218de07e\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 4d483633c04b419f9c3bb4f7c4ce0103 complete. Accuracy: 0.5566\n",
      "üèÉ View run ridge-zeros-0.0001-lambda0.1 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/4d483633c04b419f9c3bb4f7c4ce0103\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run a846e4655f8e4b4b9a84ec49f70c2827 complete. Accuracy: 0.2903\n",
      "üèÉ View run ridge-xavier-0.0001-lambda0.1 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/a846e4655f8e4b4b9a84ec49f70c2827\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run b89e13cf69e34c2a942c731f78b10fb8 complete. Accuracy: 0.5984\n",
      "üèÉ View run ridge-zeros-0.01-lambda1.0 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/b89e13cf69e34c2a942c731f78b10fb8\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run fb6158c19b194818895d9fa930c1e712 complete. Accuracy: 0.5996\n",
      "üèÉ View run ridge-xavier-0.01-lambda1.0 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/fb6158c19b194818895d9fa930c1e712\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run cd7e39b366f7448fa018f15128e1980f complete. Accuracy: 0.5664\n",
      "üèÉ View run ridge-zeros-0.001-lambda1.0 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/cd7e39b366f7448fa018f15128e1980f\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 56df73bdc7df45909fe9bedbdccb6874 complete. Accuracy: 0.5418\n",
      "üèÉ View run ridge-xavier-0.001-lambda1.0 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/56df73bdc7df45909fe9bedbdccb6874\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 6547dd3bd85f41549e98735ba4acc86d complete. Accuracy: 0.5566\n",
      "üèÉ View run ridge-zeros-0.0001-lambda1.0 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/6547dd3bd85f41549e98735ba4acc86d\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n",
      "Run 2b225b2e41854b51af60a2a373d3d112 complete. Accuracy: 0.2891\n",
      "üèÉ View run ridge-xavier-0.0001-lambda1.0 at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182/runs/2b225b2e41854b51af60a2a373d3d112\n",
      "üß™ View experiment at: http://mlflow.ml.brain.cs.ait.ac.th/#/experiments/707851046324719182\n"
     ]
    }
   ],
   "source": [
    "experiment_configs = {\n",
    "    'penalty': ['none', 'ridge'],\n",
    "    'lambda_reg': [0.01, 0.1, 1.0],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'init_method': ['zeros', 'xavier'],\n",
    "    'n_classes': 4\n",
    "}\n",
    "\n",
    "experiment_results = []\n",
    "print(\"\\nRunning classification experiments...\")\n",
    "\n",
    "for penalty in experiment_configs['penalty']:\n",
    "    for lambda_reg in experiment_configs['lambda_reg']:\n",
    "        for lr in experiment_configs['learning_rate']:\n",
    "            for init_method in experiment_configs['init_method']:\n",
    "                \n",
    "                if penalty == 'none' and lambda_reg != 0.01:\n",
    "                    continue\n",
    "\n",
    "                run_name = f\"{penalty}-{init_method}-{lr}-lambda{lambda_reg}\"\n",
    "                with mlflow.start_run(run_name=run_name) as run:\n",
    "                    # Log hyperparameters\n",
    "                    mlflow.log_param(\"penalty\", penalty)\n",
    "                    mlflow.log_param(\"lambda_reg\", lambda_reg)\n",
    "                    mlflow.log_param(\"learning_rate\", lr)\n",
    "                    mlflow.log_param(\"init_method\", init_method)\n",
    "                    \n",
    "                    model = LogisticRegression(\n",
    "                        learning_rate=lr,\n",
    "                        init_method=init_method,\n",
    "                        penalty=penalty,\n",
    "                        lambda_reg=lambda_reg,\n",
    "                        max_iter=5000 \n",
    "                    )\n",
    "                    model.fit(X_train_scaled, y_train, n_classes=experiment_configs['n_classes'])\n",
    "\n",
    "                    y_pred = model.predict(X_test_scaled)\n",
    "                    metrics = custom_classification_metrics(y_test, y_pred, n_classes=experiment_configs['n_classes'])\n",
    "                    \n",
    "                    mlflow.log_metric(\"accuracy\", metrics['accuracy'])\n",
    "                    mlflow.log_metric(\"macro_precision\", metrics['macro_precision'])\n",
    "                    mlflow.log_metric(\"macro_recall\", metrics['macro_recall'])\n",
    "                    mlflow.log_metric(\"macro_f1\", metrics['macro_f1'])\n",
    "                    mlflow.log_metric(\"weighted_f1\", metrics['weighted_f1'])\n",
    "\n",
    "                    print(f\"Run {mlflow.active_run().info.run_id} complete. Accuracy: {metrics['accuracy']:.4f}\")\n",
    "\n",
    "                    # CRITICAL FIX: Revert to saving the model with pickle and logging as a simple artifact\n",
    "                    # This bypasses the problematic mlflow.pyfunc.log_model function.\n",
    "                    model_artifacts = {\n",
    "                        'model': model,\n",
    "                        'scaler': scaler,\n",
    "                        'feature_names': feature_names,\n",
    "                        'n_classes': experiment_configs['n_classes']\n",
    "                    }\n",
    "                    \n",
    "                    with open('a3_model_artifacts.pkl', 'wb') as f:\n",
    "                        pickle.dump(model_artifacts, f)\n",
    "                    mlflow.log_artifact('a3_model_artifacts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b9b4157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best model identified!\n",
      "   Run ID: 568da67d75664803a856d7c3d8823a0f\n",
      "   Accuracy: 0.7128\n",
      "   Model artifacts saved locally and ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_name = \"st126010-a3\"\n",
    "\n",
    "# Find the experiment and best model\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "if experiment:\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[\"metrics.accuracy DESC\"],\n",
    "        max_results=1\n",
    "    )\n",
    "    \n",
    "    if runs:\n",
    "        best_run = runs[0]\n",
    "        best_accuracy = best_run.data.metrics.get('accuracy', 0)\n",
    "        \n",
    "        print(f\"‚úÖ Best model identified!\")\n",
    "        print(f\"   Run ID: {best_run.info.run_id}\")\n",
    "        print(f\"   Accuracy: {best_accuracy:.4f}\")\n",
    "        print(f\"   Model artifacts saved locally and ready for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a7620",
   "metadata": {},
   "source": [
    "### üìã Experiment Summary\n",
    "\n",
    "The goal of this assignment was to implement a custom Logistic Regression model, evaluate its performance, and compare various hyperparameters using MLflow. The following report summarizes the key findings and the performance of the best-performing model.\n",
    "\n",
    "#### Comparison Table\n",
    "\n",
    "This table compares the top models from the MLflow experiment.\n",
    "\n",
    "| Config | Accuracy | Macro Precision | Macro Recall | Macro F1 | Weighted F1 |\n",
    "|--------|----------|-----------------|--------------|----------|-------------|\n",
    "| none-xavier-0.01-lambda0.01 | 0.7128 | 0.2948 | 0.5573 | 0.2877 | 0.8051 |\n",
    "| ridge-xavier-0.01-lambda0.1 | 0.7091 | 0.2948 | 0.5564 | 0.2869 | 0.8026 |\n",
    "| none-xavier-0.01-lambda0.01 | 0.7085 | 0.2943 | 0.5562 | 0.2861 | 0.8021 |\n",
    "\n",
    "#### Key Findings\n",
    "\n",
    "1.  **Best Model Configuration**: The experiments revealed that the optimal model for this classification task was a **Logistic Regression model with Xavier initialization** and a learning rate of **0.01**. This configuration achieved the highest accuracy and overall F1-score. The model performed best without an L2 (Ridge) penalty, indicating that the original features were not prone to overfitting in this specific setup.\n",
    "2.  **Role of Initialization**: The **Xavier initialization** proved to be more effective than zeros initialization, particularly with a higher learning rate. Zeros initialization often led to slower convergence or got stuck in local minima, resulting in lower performance scores.\n",
    "3.  **Impact of Regularization**: While the goal was to test Ridge regularization, the best-performing models were those with no penalty. This suggests that the model complexity was not a primary concern for overfitting.\n",
    "4.  **Learning Rate**: The best models consistently used a learning rate of **0.01**. This value was high enough to ensure fast convergence but not so high that it caused the model's gradients to explode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5d2f6",
   "metadata": {},
   "source": [
    "#### MLflow Screenshot\n",
    "Below is a screenshot of the MLflow UI, showcasing the comparison of the top-performing runs.\n",
    "\n",
    "![MLflow experiment](MLFLOW_experiment.png)\n",
    "![Metrics](MLFLOW_scores.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc17842",
   "metadata": {},
   "source": [
    "### üìà Model Evaluation and Conclusion\n",
    "\n",
    "The classification report below provides a detailed breakdown of the best model's performance on the test set.\n",
    "\n",
    "**Classification Report of the Best Model:**\n",
    "\n",
    "![Classification Report of the Best Model](Comparison.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414154b2-798d-4990-9987-48c0c9abe197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
