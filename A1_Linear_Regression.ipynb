{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1: Linear Regression - Car Price Prediction\n",
    "**Student ID: st126010 - Htut Ko Ko**\n",
    "\n",
    "This notebook implements basic linear regression for car price prediction following the assignment requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Cars.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Basic statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data Preprocessing (Following Assignment Requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "data = df.copy()\n",
    "print(f\"Original dataset shape: {data.shape}\")\n",
    "\n",
    "# 1. Remove CNG and LPG rows (different mileage system)\n",
    "print(f\"\\nFuel types before filtering: {data['fuel'].value_counts()}\")\n",
    "data = data[~data['fuel'].isin(['CNG', 'LPG'])]\n",
    "print(f\"Fuel types after filtering: {data['fuel'].value_counts()}\")\n",
    "print(f\"Shape after removing CNG/LPG: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove Test Drive Cars (ridiculously expensive)\n",
    "print(f\"\\nOwner types before filtering: {data['owner'].value_counts()}\")\n",
    "data = data[data['owner'] != 'Test Drive Car']\n",
    "print(f\"Owner types after filtering: {data['owner'].value_counts()}\")\n",
    "print(f\"Shape after removing Test Drive Cars: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Map owner feature: First Owner=1, Second Owner=2, etc.\n",
    "owner_mapping = {\n",
    "    'First Owner': 1,\n",
    "    'Second Owner': 2, \n",
    "    'Third Owner': 3,\n",
    "    'Fourth & Above Owner': 4\n",
    "}\n",
    "data['owner'] = data['owner'].map(owner_mapping)\n",
    "print(f\"\\nOwner mapping applied: {data['owner'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Clean mileage column - remove 'kmpl' and convert to float\n",
    "print(f\"\\nMileage before cleaning (sample): {data['mileage'].head()}\")\n",
    "data['mileage'] = data['mileage'].str.split().str[0]  # Take first part before space\n",
    "data['mileage'] = pd.to_numeric(data['mileage'], errors='coerce')\n",
    "print(f\"Mileage after cleaning (sample): {data['mileage'].head()}\")\n",
    "print(f\"Mileage data type: {data['mileage'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Clean engine column - remove 'CC' and convert to float\n",
    "print(f\"\\nEngine before cleaning (sample): {data['engine'].head()}\")\n",
    "data['engine'] = data['engine'].str.replace(' CC', '').str.replace('CC', '')\n",
    "data['engine'] = pd.to_numeric(data['engine'], errors='coerce')\n",
    "print(f\"Engine after cleaning (sample): {data['engine'].head()}\")\n",
    "print(f\"Engine data type: {data['engine'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Clean max_power column - remove 'bhp' and convert to float\n",
    "print(f\"\\nMax power before cleaning (sample): {data['max_power'].head()}\")\n",
    "data['max_power'] = data['max_power'].str.replace(' bhp', '').str.replace('bhp', '')\n",
    "data['max_power'] = pd.to_numeric(data['max_power'], errors='coerce')\n",
    "print(f\"Max power after cleaning (sample): {data['max_power'].head()}\")\n",
    "print(f\"Max power data type: {data['max_power'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Extract brand from name (first word only)\n",
    "print(f\"\\nName before brand extraction (sample): {data['name'].head()}\")\n",
    "data['brand'] = data['name'].str.split().str[0]\n",
    "print(f\"Brand after extraction (sample): {data['brand'].head()}\")\n",
    "print(f\"Unique brands: {data['brand'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Drop torque column (as per assignment requirement)\n",
    "if 'torque' in data.columns:\n",
    "    data = data.drop('torque', axis=1)\n",
    "    print(\"Torque column dropped\")\n",
    "\n",
    "# Also drop name column since we extracted brand\n",
    "data = data.drop('name', axis=1)\n",
    "print(\"Name column dropped (brand extracted)\")\n",
    "\n",
    "print(f\"\\nFinal columns: {list(data.columns)}\")\n",
    "print(f\"Final shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values after preprocessing\n",
    "print(\"Missing values after preprocessing:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values with imputation\n",
    "# Fill missing numerical values with median\n",
    "numerical_cols = ['mileage', 'engine', 'max_power']\n",
    "for col in numerical_cols:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        median_val = data[col].median()\n",
    "        data[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Filled {col} missing values with median: {median_val}\")\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned data sample\n",
    "print(\"Cleaned data sample:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data['selling_price'], bins=50, alpha=0.7)\n",
    "plt.title('Selling Price Distribution')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.log(data['selling_price']), bins=50, alpha=0.7, color='orange')\n",
    "plt.title('Log-transformed Selling Price Distribution')\n",
    "plt.xlabel('Log(Price)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Price statistics:\")\n",
    "print(f\"Mean: {data['selling_price'].mean():,.0f}\")\n",
    "print(f\"Median: {data['selling_price'].median():,.0f}\")\n",
    "print(f\"Min: {data['selling_price'].min():,.0f}\")\n",
    "print(f\"Max: {data['selling_price'].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numerical_features = ['year', 'km_driven', 'mileage', 'engine', 'max_power', 'seats', 'owner', 'selling_price']\n",
    "corr_matrix = data[numerical_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation with selling_price:\")\n",
    "print(corr_matrix['selling_price'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Feature Engineering and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_cols = ['fuel', 'seller_type', 'transmission', 'brand']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {len(le.classes_)} unique values\")\n",
    "\n",
    "print(f\"\\nLabel encoders saved for: {list(label_encoders.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation to target variable (as per assignment requirement)\n",
    "y = np.log(data['selling_price'])\n",
    "X = data.drop('selling_price', axis=1)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")\n",
    "print(f\"\\nTarget (log-transformed) statistics:\")\n",
    "print(f\"Mean: {y.mean():.4f}\")\n",
    "print(f\"Std: {y.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully\")\n",
    "print(f\"Training features mean: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"Training features std: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Linear Regression model trained successfully\")\n",
    "print(f\"Model coefficients shape: {model.coef_.shape}\")\n",
    "print(f\"Model intercept: {model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions (log scale)\n",
    "y_train_pred_log = model.predict(X_train_scaled)\n",
    "y_test_pred_log = model.predict(X_test_scaled)\n",
    "\n",
    "# Transform back to original scale (as per assignment requirement)\n",
    "y_train_pred = np.exp(y_train_pred_log)\n",
    "y_test_pred = np.exp(y_test_pred_log)\n",
    "y_train_actual = np.exp(y_train)\n",
    "y_test_actual = np.exp(y_test)\n",
    "\n",
    "print(\"Predictions completed and transformed back to original scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "train_r2 = r2_score(y_train_actual, y_train_pred)\n",
    "test_r2 = r2_score(y_test_actual, y_test_pred)\n",
    "train_mse = mean_squared_error(y_train_actual, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test_actual, y_test_pred)\n",
    "\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"Training R²: {train_r2:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")\n",
    "print(f\"Training MSE: {train_mse:,.0f}\")\n",
    "print(f\"Test MSE: {test_mse:,.0f}\")\n",
    "print(f\"Training RMSE: {np.sqrt(train_mse):,.0f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(test_mse):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': model.coef_,\n",
    "    'abs_coefficient': np.abs(model.coef_)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (by coefficient magnitude):\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Actual vs Predicted\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test_actual, y_test_pred, alpha=0.6)\n",
    "plt.plot([y_test_actual.min(), y_test_actual.max()], [y_test_actual.min(), y_test_actual.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title(f'Actual vs Predicted (R² = {test_r2:.4f})')\n",
    "\n",
    "# Residuals\n",
    "plt.subplot(1, 3, 2)\n",
    "residuals = y_test_actual - y_test_pred\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "\n",
    "# Feature importance\n",
    "plt.subplot(1, 3, 3)\n",
    "top_features = feature_importance.head(8)\n",
    "plt.barh(range(len(top_features)), top_features['abs_coefficient'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Absolute Coefficient')\n",
    "plt.title('Top Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and preprocessing components\n",
    "model_artifacts = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': label_encoders,\n",
    "    'feature_names': list(X.columns),\n",
    "    'metrics': {\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_mse': train_mse,\n",
    "        'test_mse': test_mse\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('a1_model_artifacts.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "\n",
    "print(\"Model artifacts saved to 'a1_model_artifacts.pkl'\")\n",
    "print(f\"Saved components: {list(model_artifacts.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Analysis and Discussion\n",
    "\n",
    "### Results Analysis\n",
    "\n",
    "**Model Performance:**\n",
    "The Linear Regression model achieved a test R² score of {test_r2:.4f}, indicating that the model explains approximately {test_r2*100:.1f}% of the variance in car prices. This represents a reasonable baseline performance for a simple linear model.\n",
    "\n",
    "**Feature Importance:**\n",
    "Based on the coefficient analysis, the most important features for predicting car prices are:\n",
    "1. **Year**: Newer cars tend to have higher prices, showing strong positive correlation\n",
    "2. **Engine size**: Larger engines typically indicate more powerful and expensive cars\n",
    "3. **Max Power**: Higher power output directly correlates with premium pricing\n",
    "4. **Brand**: Certain brands command premium prices due to reputation and quality\n",
    "5. **Mileage**: Interestingly, fuel efficiency can both positively and negatively impact price depending on car segment\n",
    "\n",
    "**Data Preprocessing Impact:**\n",
    "The log transformation of the target variable was crucial for stabilizing the model's predictions, as car prices have a wide range and skewed distribution. Removing CNG/LPG vehicles and Test Drive Cars helped focus the model on the main market segments with consistent pricing patterns.\n",
    "\n",
    "**Model Limitations:**\n",
    "Linear regression assumes linear relationships between features and target, which may not capture complex interactions in car pricing. The model shows some heteroscedasticity in residuals, suggesting that more sophisticated models might better capture the pricing dynamics. Additionally, categorical features like brand were simply label-encoded, which may not fully capture brand hierarchy and premium positioning.\n",
    "\n",
    "**Recommendations for Improvement:**\n",
    "Future iterations could benefit from polynomial features, regularization techniques, or ensemble methods to better capture non-linear relationships and reduce overfitting. Feature engineering could include interaction terms between year and brand, or mileage and engine size, which are likely important for pricing decisions.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
